{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"english_german.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/alexgaskell10/NLP_Translation/blob/master/notebooks/stuff.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","metadata":{"id":"hpAd9yKPDnlI","colab_type":"code","outputId":"8045c332-5029-47df-ef3f-133efcd3b2b3","executionInfo":{"status":"ok","timestamp":1581365387595,"user_tz":0,"elapsed":6459,"user":{"displayName":"Alex Gaskell","photoUrl":"","userId":"12223185016372309013"}},"colab":{"base_uri":"https://localhost:8080/","height":625}},"source":["! pip install transformers"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n","\u001b[K     |████████████████████████████████| 481kB 3.4MB/s \n","\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.10)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 64.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.0.11\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.1MB 45.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 50.1MB/s \n","\u001b[?25hRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n","Requirement already satisfied: botocore<1.15.0,>=1.14.10 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.10)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.2)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.10->boto3->transformers) (2.6.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=32d50dfe04b670168ebd20f1b6b16a4ebf103c7be3c65bcfd81293efaebee9ac\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8yKxJ_GREs_C","colab_type":"code","colab":{}},"source":["import torch\n","from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n","from sklearn.model_selection import train_test_split\n","from torch.nn import Linear\n","from torch import optim\n","import random\n","import time\n","import numpy as np\n","from scipy.stats import pearsonr\n","import matplotlib.pyplot as plt\n","torch.set_printoptions(4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"scs7ICZrPFcs","colab_type":"code","colab":{}},"source":["# Download and unzip the data\n","from os.path import exists\n","if not exists('ende_data.zip'):\n","    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n","    !unzip ende_data.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yotBQbegEtVA","colab_type":"code","colab":{}},"source":["# Load data into variables\n","with open(\"./train.ende.src\", \"r\") as ende_src:\n","    en_corpus = ende_src.read().split('\\n')[:-1]\n","with open(\"./train.ende.mt\", \"r\") as ende_src:\n","    de_corpus = ende_src.read().split('\\n')[:-1]\n","with open(\"./train.ende.scores\", \"r\") as ende_src:\n","    scores = [float(x) for x in ende_src.read().split('\\n')[:-1]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_0sUlc8nuOeT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":284},"outputId":"46e833c5-7481-4abd-d4ca-37139da8962d","executionInfo":{"status":"ok","timestamp":1581365460942,"user_tz":0,"elapsed":624,"user":{"displayName":"Alex Gaskell","photoUrl":"","userId":"12223185016372309013"}}},"source":["plt.plot(sorted(scores))\n","plt.ylim([-2,2])"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(-2, 2)"]},"metadata":{"tags":[]},"execution_count":10},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"rvu5GAlL5-wc","colab_type":"code","colab":{}},"source":["class Preprocessor:\n","    def __init__(self, device, bert_config):\n","        self.device = device\n","        self.tokenizer = BertTokenizer.from_pretrained(bert_config)\n","\n","    def get_input_tensor(self, en_corpus, de_corpus):\n","        # Convert input sequences to correct format\n","        N = len(en_corpus)\n","\n","        # Tokenize corpora\n","        inputs_en, inputs_de = [],[]\n","        max_len_en, max_len_de = 0,0\n","            \n","        for i in range(N):\n","            # English\n","            seq = en_corpus[i][:-1]\n","            input_ids = torch.tensor([self.tokenizer.encode(seq, add_special_tokens=True)])\n","            inputs_en.append(input_ids)\n","            if input_ids.shape[-1] > max_len_en:\n","                max_len_en = input_ids.shape[-1]\n","\n","            # German\n","            seq = de_corpus[i][:-1]\n","            input_ids = torch.tensor([self.tokenizer.encode(seq, add_special_tokens=True)])\n","            inputs_de.append(input_ids)\n","            if input_ids.shape[-1] > max_len_de:\n","                max_len_de = input_ids.shape[-1]\n","\n","        # Combine tokens into single tensor\n","        inp_tensor = torch.zeros((N, max_len_en + max_len_de - 2))      # <-- -2 because special tokens are not necessary at beginning of German sequence\n","\n","        for i in range(N):\n","            # Add English tokens\n","            en_tokens = inputs_en[i].squeeze()\n","            inp_tensor[i, : len(en_tokens)] = en_tokens\n","\n","            # Add German tokens\n","            de_tokens = inputs_de[i][:,2:].squeeze()      # <-- ignore first 2 tokens as these are special tokens and unnecessary in this case\n","            inp_tensor[i, max_len_en : max_len_en + len(de_tokens)] = de_tokens\n","\n","        return inp_tensor\n","\n","    def attention_mask(self, list_input_tensor):\n","        list_attention_masks = []\n","        for input_tensor in list_input_tensor:\n","            attention_mask = torch.zeros((input_tensor.shape))\n","            attention_mask[input_tensor != 0] = 1\n","            list_attention_masks.append(attention_mask)\n","\n","        return list_attention_masks\n","\n","    def get_batches(self, inp_tensor, scores, BATCH_N):\n","        inp_tensor = inp_tensor\n","        scores = torch.tensor(scores).view(-1,1)\n","\n","        # Split data into train, test and val batches\n","        inp_tensor_batches = torch.split(inp_tensor, BATCH_N)\n","        scores_batches = torch.split(scores, BATCH_N)\n","        X_train_val, X_test, y_train_val, y_test = train_test_split(inp_tensor_batches, scores_batches, random_state=1, test_size=0.1)\n","        X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=1, test_size=1/9)\n","        print(len(X_train), X_train[0].shape)\n","\n","        # Create attention masks\n","        X_train_mask = self.attention_mask(X_train)\n","        X_val_mask = self.attention_mask(X_val) \n","        X_test_mask = self.attention_mask(X_test)\n","        print(len(X_train_mask), X_train_mask[0].shape)\n","\n","        # Batch X, mask and y together\n","        batches_train = [(X, mask, y) for X,mask,y in zip(X_train, X_train_mask, y_train)]\n","        batches_val = [(X, mask, y) for X,mask,y in zip(X_val, X_val_mask, y_val)]\n","        batches_test = [(X, mask, y) for X,mask,y in zip(X_test, X_test_mask, y_test)]\n","\n","        return batches_train, batches_val, batches_test\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LWG59VN-23aV","colab_type":"code","colab":{}},"source":["class BertRegressor:\n","    def __init__(self, input_shape, bert_config, device):\n","        self.device = device\n","        self.bert = BertModel.from_pretrained(bert_config).to(device)\n","        self.linear = Linear(in_features = input_shape[-1] * 768,                   # <-- 768 is the dim of Bert embedding\n","                             out_features = 1, bias = True).to(device)\n","\n","    def forward(self, X, attention_mask=None):\n","        if attention_mask is not None:\n","            X = self.bert(X, attention_mask)[0].view(X.shape[0], -1)    \n","        else:\n","            X = self.bert(X)[0].view(X.shape[0], -1)\n","\n","        preds = self.linear(X)\n","        return preds\n","\n","    def loss(self, scores, pred_scores):\n","        rmse = (((pred_scores - scores)**2).mean())**0.5\n","        return rmse\n","\n","    def check_r(self, y_pred, y):\n","        return pearsonr(y_pred.cpu().squeeze(), y.cpu().squeeze())[0]\n","\n","    def zero_grad(self):\n","        self.bert.zero_grad()\n","        self.linear.zero_grad()\n","\n","    def params(self):\n","        return list(self.bert.parameters()) + list(self.linear.parameters())\n","\n","    def __call__(self, X, attention_mask=None):\n","        return self.forward(X, attention_mask)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Rp7NCpb-9NL-","outputId":"91d13400-dff2-43c5-b7bc-c48770552b45","executionInfo":{"status":"ok","timestamp":1581338082306,"user_tz":0,"elapsed":5484,"user":{"displayName":"Alex Gaskell","photoUrl":"","userId":"12223185016372309013"}},"colab":{"base_uri":"https://localhost:8080/","height":49}},"source":["USE_GPU = True\n","\n","if USE_GPU and torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","\n","bert_config = 'bert-base-multilingual-cased'\n","BATCH_N = 32\n","EPOCHS = 4\n","LR = 2e-5\n","\n","# Set seeds\n","seed_val = 111\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# Preprocessing\n","preprocessor = Preprocessor(device, bert_config)\n","input_tensor = preprocessor.get_input_tensor(en_corpus, de_corpus)\n","batches_train, batches_val, batches_test = preprocessor.get_batches(input_tensor, scores, BATCH_N)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["175 torch.Size([32, 132])\n","175 torch.Size([32, 132])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4m8jwjBaCsAJ","colab_type":"code","outputId":"5fff81b9-a589-48cb-e14d-c17e84306aff","executionInfo":{"status":"ok","timestamp":1581338132989,"user_tz":0,"elapsed":4050,"user":{"displayName":"Alex Gaskell","photoUrl":"","userId":"12223185016372309013"}},"colab":{"base_uri":"https://localhost:8080/","height":32}},"source":["# torch.cuda.empty_cache()\n","# model = BertRegressor(batches_train[0][0].shape, bert_config, device)\n","\n","# X = batches_train[0][0].to(device, dtype=torch.long)\n","# mask = batches_train[0][1].to(device)\n","# # print(X.device, mask.device, X.requires_grad)\n","# model(X, mask).shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 1])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"8306qtg603CS","colab_type":"code","colab":{}},"source":["def validation(val_batches):\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","    eval_loss = 0\n","    correlations = []\n","\n","    for batch in val_batches:        \n","\n","        # Untie batch and put on GPU\n","        X = batch[0].to(device=device, dtype=torch.long)\n","        mask = batch[1].to(device)\n","        y = batch[2].to(device)\n","\n","        with torch.no_grad():        \n","            y_pred = model(X)                      \n","                \n","        # Compute and record batch accuracy\n","        corr = model.check_r(y_pred, y)\n","        correlations.append(corr)\n","\n","    # Report the final accuracy for this validation run.\n","    print(f\"|  Correlation: {np.mean(correlations):.2f}     |\")\n","    print(f\"|  Validation took: {time.time() - t0:0f} s |\")\n","\n","    torch.cuda.empty_cache()\n","\n","\n","def train(model, train_batches, val_batches, epochs):\n","\n","    losses = []\n","    \n","    for epoch_i in range(epochs):\n","        \n","        print(\"\")\n","        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","        print('Training...')\n","\n","        t0 = time.time()\n","        total_loss = 0\n","\n","        for step, batch in enumerate(train_batches):\n","\n","            if step % 20 == 0 and not step == 0:\n","                # Progress update every 40 batches                \n","                print('  Batch {:>5,}  of  {:>5,}    |    Elapsed: {:.0f}s.'.format(step, len(train_batches), time.time() - t0))\n","\n","            # Untie batch and put on GPU\n","            X = batch[0].to(device=device, dtype=torch.long)\n","            mask = batch[1].to(device)\n","            y = batch[2].to(device)\n","\n","            model.zero_grad()                   # Reset grads\n","            y_pred = model(X, mask)             # Forward pass\n","            loss = model.loss(y, y_pred)        # Compute loss\n","            total_loss += loss.item()           # Accumulate loss\n","            loss.backward()                     # Backward pass\n","\n","            optimizer.step()                    # Update params\n","            scheduler.step()                    # Update optimizer\n","\n","            torch.cuda.empty_cache()            # Clear GPU cache to avoid memory issues\n","\n","        # Compute and store avg loss\n","        avg_train_loss = total_loss / len(X)\n","        losses.append(avg_train_loss)\n","\n","        print(\"\")\n","        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","        print(\"  Training epoch took: {:.0f}s\".format(time.time() - t0))\n","\n","        validation(val_batches) \n","\n","    print(\"\")\n","    print(\"Training complete!\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixlL-kPPtjZv","colab_type":"code","outputId":"9afcd6e3-01d2-444c-f684-b4cc57fba48c","executionInfo":{"status":"error","timestamp":1581339011592,"user_tz":0,"elapsed":140723,"user":{"displayName":"Alex Gaskell","photoUrl":"","userId":"12223185016372309013"}},"colab":{"base_uri":"https://localhost:8080/","height":776}},"source":["# Model to train\n","model = BertRegressor(batches_train[0][0].shape, bert_config, device)\n","\n","# Optimizer and scheduler\n","optimizer = AdamW(model.params(), lr=LR, eps=1e-8)\n","total_steps = len(batches_train[0]) * EPOCHS // BATCH_N\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)\n","\n","torch.cuda.empty_cache()\n","train(model, batches_train[:60], batches_val[:60], epochs=EPOCHS)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    20  of     60    |    Elapsed: 18s.\n","  Batch    40  of     60    |    Elapsed: 36s.\n","\n","  Average training loss: 1.57\n","  Training epcoh took: 55s\n","\n","Running Validation...\n","|  Correlation: -0.05     |\n","|  Validation took: 6.016750 s |\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    20  of     60    |    Elapsed: 18s.\n","  Batch    40  of     60    |    Elapsed: 36s.\n","\n","  Average training loss: 1.57\n","  Training epcoh took: 54s\n","\n","Running Validation...\n","|  Correlation: -0.05     |\n","|  Validation took: 6.076826 s |\n","\n","======== Epoch 3 / 4 ========\n","Training...\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-f9c77e113258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-33-17f44415bedd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_batches, val_batches, epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# Accumulate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                    \u001b[0;31m# Update params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"__5QoNXSsz38","colab_type":"code","colab":{}},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","    "],"execution_count":0,"outputs":[]}]}